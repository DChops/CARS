{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarClassifier(BaseEstimator):\n",
    "    def __init__(self,minsup=0.3,minconf=0.7):\n",
    "        self.minsup = minsup\n",
    "        self.minconf = minconf\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        # Check that X.shape[0]==y.shape[0] \n",
    "        # X, y = check_X_y(X, y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        rules = self.build_()\n",
    "        self.cover_(rules)\n",
    "\n",
    "        return True\n",
    "\n",
    "    def predict(self,X):\n",
    "        # Check that fit has been called\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        for i in self.rules.index:\n",
    "            ans = self.predict_compare(self.rules.loc[i],X)\n",
    "            if(ans==-1):\n",
    "                continue\n",
    "            else:\n",
    "                return ans\n",
    "\n",
    "        return self.maj\n",
    "\n",
    "    def predict_compare(self,df1,df2):\n",
    "        without = list(df1.index)\n",
    "        without.remove(self.y_.name)\n",
    "        without.remove('sup')\n",
    "        without.remove('rsup')\n",
    "        without.remove('acc')\n",
    "        without.remove('err')\n",
    "        without.remove('maj')\n",
    "        for i in without:\n",
    "            if(not pd.isnull(df1[i]) and df1[i]!=df2[i]):\n",
    "                return -1\n",
    "        \n",
    "        return df1[self.y_.name]\n",
    "\n",
    "\n",
    "    def build_(self) -> dict:\n",
    "        rules = dict()\n",
    "        temp_rules = self.initial_build_()\n",
    "        self.transfer_dict(rules,temp_rules)\n",
    "\n",
    "        while(self.isempty(temp_rules)):\n",
    "            candidates = self.gen_new_cand(temp_rules)\n",
    "            temp_rules = self.prune_rules(candidates)\n",
    "            self.transfer_dict(rules,temp_rules)\n",
    "\n",
    "        return rules\n",
    "    \n",
    "    def isempty(self,rules:dict) -> int:\n",
    "        for i in rules:\n",
    "            if(rules[i]!=[]):\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    def initial_build_(self) -> dict:\n",
    "        temp_rules = dict()\n",
    "        for i in self.X_:\n",
    "            vals = pd.concat([self.X_[i],self.y_],axis=1,names=[\"pred\",\"resp\"]).value_counts()\n",
    "            val = self.X_[i].value_counts()\n",
    "            for j in vals.index:\n",
    "                if(val[j[0]]>=self.minsup and vals[j]/val[j[0]]>=self.minconf):\n",
    "                    if(j[1] not in temp_rules):\n",
    "                        temp_rules[j[1]] = list()\n",
    "                        \n",
    "                    temp_rules[j[1]].append({\n",
    "                        \"pred\":{i:j[0]},\n",
    "                        \"sup\":val[j[0]],\n",
    "                        \"rsup\":vals[j]\n",
    "                    })\n",
    "                    \n",
    "        return temp_rules\n",
    "\n",
    "    def gen_new_cand(self,temp_rules) -> dict:\n",
    "        cands = dict()\n",
    "        for i in temp_rules:\n",
    "            cands[i] = list()\n",
    "            l = self.comb_cand(temp_rules[i])\n",
    "            self.add_support(l,i)\n",
    "            cands[i] = cands[i] + l\n",
    "        return cands\n",
    "\n",
    "\n",
    "    def transfer_dict(self,dict1,dict2) -> None:\n",
    "        for i in dict2:\n",
    "            if(i not in dict1):\n",
    "                dict1[i] = list()\n",
    "            dict1[i].append(dict2[i])\n",
    "\n",
    "    def combine_dict(self,dict1,dict2) -> dict:\n",
    "        temp = dict()\n",
    "        for i in dict1:\n",
    "            temp[i] = dict1[i]\n",
    "        for i in dict2:\n",
    "            temp[i] = dict2[i]\n",
    "        return temp\n",
    "\n",
    "\n",
    "    def comb_cand(self,cand:list) -> list:\n",
    "        cands = list()\n",
    "        for i in range(len(cand)):\n",
    "            for j in range(i+1,len(cand)):\n",
    "                comp1 = sorted(list(cand[i][\"pred\"].keys()))[:-1]\n",
    "                comp2 = sorted(list(cand[j][\"pred\"].keys()))[:-1]\n",
    "                if(comp1==comp2):\n",
    "                    cands.append({\n",
    "                        \"pred\":self.combine_dict(cand[i][\"pred\"],cand[j][\"pred\"])\n",
    "                    })\n",
    "        return cands\n",
    "\n",
    "    def add_support(self, l:list, y):\n",
    "        for i in l:\n",
    "            i[\"sup\"], i[\"rsup\"] = self.getsup(i,y)\n",
    "\n",
    "    def getsup(self, diction:dict,y) -> int:\n",
    "        filterList = list(diction[\"pred\"].items())\n",
    "        _Xy = pd.concat([self.X_,self.y_],axis=1)\n",
    "        for t in filterList:\n",
    "            _Xy = _Xy[_Xy[t[0]]==t[1]]\n",
    "        \n",
    "        ans1 = len(_Xy)\n",
    "        ans2 = len((_Xy[_Xy[self.y_.name]==y]))\n",
    "\n",
    "        return ans1, ans2\n",
    "\n",
    "    def prune_rules(self,candidates):\n",
    "        return candidates\n",
    "\n",
    "    def cover_(self, rules: dict) -> None:\n",
    "        df_rules = self.pre_cover(rules)\n",
    "        _Xy = pd.concat([self.X_,self.y_],axis=1)\n",
    "        final_rules = pd.DataFrame(columns=df_rules.columns)\n",
    "        final_rules[\"err\"] = 0\n",
    "        final_rules[\"maj\"] = 0\n",
    "        \n",
    "        for i in df_rules.index:\n",
    "            if(len(_Xy)==0):\n",
    "                break\n",
    "            sup = 0\n",
    "            err = 0\n",
    "            pre_index =  _Xy.index\n",
    "            for j in pre_index:\n",
    "                sup_plus,err_plus = self.compare(df_rules.loc[i],_Xy.loc[j])\n",
    "                if(sup_plus):\n",
    "                    _Xy.drop(j,axis=0,inplace=True)\n",
    "                    sup = sup + sup_plus\n",
    "                    err = err + err_plus \n",
    "                    \n",
    "            if(len(_Xy)!=0):\n",
    "                vals = _Xy[self.y_.name].value_counts()\n",
    "                majority = vals[vals.index[0]]\n",
    "                err_extra = len(_Xy) - majority\n",
    "                err = err + err_extra\n",
    "                \n",
    "            if(sup!=0):\n",
    "                new_df = df_rules[df_rules.index==i]\n",
    "                # new_df[\"err\"] = err\n",
    "                # new_df[\"maj\"] = vals.index[0]\n",
    "                new_df = new_df.assign(err = lambda x: (err))\n",
    "                new_df = new_df.assign(maj = lambda x: (vals.index[0]))\n",
    "                final_rules = pd.concat([final_rules,new_df],axis=0)\n",
    "        \n",
    "        self.rules = pd.DataFrame(columns=df_rules.columns)\n",
    "        self.rules[\"err\"] = 0\n",
    "        self.rules[\"maj\"] = 0\n",
    "\n",
    "        min_err = min(final_rules[\"err\"])\n",
    "        for i in final_rules.index:\n",
    "            if(final_rules.at[i,\"err\"]==min_err):\n",
    "                self.maj = (final_rules[final_rules.index==i])[\"maj\"]\n",
    "                break\n",
    "            self.rules = pd.concat([self.rules,final_rules[final_rules.index==i]],axis=0)\n",
    "\n",
    "            \n",
    "\n",
    "    def compare(self,df1,df2)->int:\n",
    "        without_y = list(df1.index)\n",
    "        without_y.remove(self.y_.name)\n",
    "        without_y.remove('sup')\n",
    "        without_y.remove('rsup')\n",
    "        without_y.remove('acc')\n",
    "        for i in without_y:\n",
    "            if(not pd.isnull(df1[i]) and df1[i]!=df2[i]):\n",
    "                return 0,0\n",
    "        \n",
    "        if(df1[self.y_.name]==df2[self.y_.name]):\n",
    "            return 1,0  # rule with no errors\n",
    "        else:\n",
    "            return 1,1  # rule with error\n",
    "\n",
    "\n",
    "    def pre_cover(self,rules:dict) -> pd.DataFrame:\n",
    "        arr = []\n",
    "        for i in rules:\n",
    "            for j in rules[i]:\n",
    "                for k in j:\n",
    "                    k[self.y_.name] = i\n",
    "                    arr.append(k)\n",
    "        dat = pd.json_normalize(arr)\n",
    "        dat[\"acc\"] = dat[\"rsup\"]/dat[\"sup\"]\n",
    "        dat.sort_values(by=[\"acc\",\"sup\"],ascending=False, inplace=True)\n",
    "        \n",
    "        cols = list(dat.columns)\n",
    "        for i in range(len(cols)):\n",
    "            cols[i] = cols[i].replace(\"pred.\",\"\")\n",
    "        dat.columns = cols\n",
    "        \n",
    "        return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    " \n",
    "titanic = fetch_openml('titanic', version=1, as_frame=True)\n",
    "data = titanic['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zabour, Miss. Hileni</td>\n",
       "      <td>female</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>328.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zabour, Miss. Thamine</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zakarian, Mr. Mapriededer</td>\n",
       "      <td>male</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2656</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>304.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zakarian, Mr. Ortin</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2670</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zimmerman, Mr. Leo</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315082</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass                                             name     sex  \\\n",
       "0        1.0                    Allen, Miss. Elisabeth Walton  female   \n",
       "1        1.0                   Allison, Master. Hudson Trevor    male   \n",
       "2        1.0                     Allison, Miss. Helen Loraine  female   \n",
       "3        1.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4        1.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "...      ...                                              ...     ...   \n",
       "1304     3.0                             Zabour, Miss. Hileni  female   \n",
       "1305     3.0                            Zabour, Miss. Thamine  female   \n",
       "1306     3.0                        Zakarian, Mr. Mapriededer    male   \n",
       "1307     3.0                              Zakarian, Mr. Ortin    male   \n",
       "1308     3.0                               Zimmerman, Mr. Leo    male   \n",
       "\n",
       "          age  sibsp  parch  ticket      fare    cabin embarked  boat   body  \\\n",
       "0     29.0000    0.0    0.0   24160  211.3375       B5        S     2    NaN   \n",
       "1      0.9167    1.0    2.0  113781  151.5500  C22 C26        S    11    NaN   \n",
       "2      2.0000    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
       "3     30.0000    1.0    2.0  113781  151.5500  C22 C26        S  None  135.0   \n",
       "4     25.0000    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
       "...       ...    ...    ...     ...       ...      ...      ...   ...    ...   \n",
       "1304  14.5000    1.0    0.0    2665   14.4542     None        C  None  328.0   \n",
       "1305      NaN    1.0    0.0    2665   14.4542     None        C  None    NaN   \n",
       "1306  26.5000    0.0    0.0    2656    7.2250     None        C  None  304.0   \n",
       "1307  27.0000    0.0    0.0    2670    7.2250     None        C  None    NaN   \n",
       "1308  29.0000    0.0    0.0  315082    7.8750     None        S  None    NaN   \n",
       "\n",
       "                            home.dest  \n",
       "0                        St Louis, MO  \n",
       "1     Montreal, PQ / Chesterville, ON  \n",
       "2     Montreal, PQ / Chesterville, ON  \n",
       "3     Montreal, PQ / Chesterville, ON  \n",
       "4     Montreal, PQ / Chesterville, ON  \n",
       "...                               ...  \n",
       "1304                             None  \n",
       "1305                             None  \n",
       "1306                             None  \n",
       "1307                             None  \n",
       "1308                             None  \n",
       "\n",
       "[1309 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pd.DataFrame(columns=data.columns)\n",
    "X2['sepal length (cm)'] = pd.qcut(X['sepal length (cm)'], q=3, precision=0, labels=[\"low\",\"medium\",\"high\"])\n",
    "X2['sepal width (cm)'] = pd.qcut(X['sepal width (cm)'], q=3, precision=0, labels=[\"low\",\"medium\",\"high\"])\n",
    "X2['petal length (cm)'] = pd.qcut(X['petal length (cm)'], q=3, precision=0, labels=[\"low\",\"medium\",\"high\"])\n",
    "X2['petal width (cm)'] = pd.qcut(X['petal width (cm)'], q=3, precision=0, labels=[\"low\",\"medium\",\"high\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
